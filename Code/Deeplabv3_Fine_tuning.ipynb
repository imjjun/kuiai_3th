{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["#Human Segmentation Fine Tuning\n","\n","Dataset TItle: People Clothing Segmentation from kaggle\n","\n","Dataset Reference: https://www.kaggle.com/datasets/rajkumarl/people-clothing-segmentation\n","\n","Code Reference: https://github.com/msminhas93/DeepLabv3FineTuning"],"metadata":{"id":"ESpb1B0K4_Lx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JGK0QUjrerhN"},"outputs":[],"source":["import torch\n","import torchvision\n","from torchvision.datasets.vision import VisionDataset\n","\n","import numpy as np\n","from PIL import Image\n","\n","from pathlib import Path\n","from typing import Any, Callable, Optional\n","\n","#Dataset Definition\n","#Same with Reference Code\n","\n","class SegmentationDataset(VisionDataset):\n","    \n","    def __init__(self,\n","                 root: str,\n","                 image_folder: str,\n","                 mask_folder: str,\n","                 transforms: Optional[Callable] = None,\n","                 seed: int = None,\n","                 fraction: float = None,\n","                 subset: str = None,\n","                 image_color_mode: str = \"rgb\",\n","                 mask_color_mode: str = \"grayscale\") -> None:\n","        \"\"\"\n","        Args:\n","            root (str): Root directory path.\n","            image_folder (str): Name of the folder that contains the images in the root directory.\n","            mask_folder (str): Name of the folder that contains the masks in the root directory.\n","            transforms (Optional[Callable], optional): A function/transform that takes in\n","            a sample and returns a transformed version.\n","            E.g, ``transforms.ToTensor`` for images. Defaults to None.\n","            seed (int, optional): Specify a seed for the train and test split for reproducible results. Defaults to None.\n","            fraction (float, optional): A float value from 0 to 1 which specifies the validation split fraction. Defaults to None.\n","            subset (str, optional): 'Train' or 'Test' to select the appropriate set. Defaults to None.\n","            image_color_mode (str, optional): 'rgb' or 'grayscale'. Defaults to 'rgb'.\n","            mask_color_mode (str, optional): 'rgb' or 'grayscale'. Defaults to 'grayscale'.\n","        Raises:\n","            OSError: If image folder doesn't exist in root.\n","            OSError: If mask folder doesn't exist in root.\n","            ValueError: If subset is not either 'Train' or 'Test'\n","            ValueError: If image_color_mode and mask_color_mode are either 'rgb' or 'grayscale'\n","        \"\"\"\n","        super().__init__(root, transforms)\n","        image_folder_path = Path(self.root) / image_folder\n","        mask_folder_path = Path(self.root) / mask_folder\n","        if not image_folder_path.exists():\n","            raise OSError(f\"{image_folder_path} does not exist.\")\n","        if not mask_folder_path.exists():\n","            raise OSError(f\"{mask_folder_path} does not exist.\")\n","\n","        if image_color_mode not in [\"rgb\", \"grayscale\"]:\n","            raise ValueError(\n","                f\"{image_color_mode} is an invalid choice. Please enter from rgb grayscale.\"\n","            )\n","        if mask_color_mode not in [\"rgb\", \"grayscale\"]:\n","            raise ValueError(\n","                f\"{mask_color_mode} is an invalid choice. Please enter from rgb grayscale.\"\n","            )\n","\n","        self.image_color_mode = image_color_mode\n","        self.mask_color_mode = mask_color_mode\n","\n","        if not fraction:\n","            self.image_names = sorted(image_folder_path.glob(\"*\"))\n","            self.mask_names = sorted(mask_folder_path.glob(\"*\"))\n","        else:\n","            if subset not in [\"Train\", \"Test\"]:\n","                raise (ValueError(\n","                    f\"{subset} is not a valid input. Acceptable values are Train and Test.\"\n","                ))\n","            self.fraction = fraction\n","            self.image_list = np.array(sorted(image_folder_path.glob(\"*\")))\n","            self.mask_list = np.array(sorted(mask_folder_path.glob(\"*\")))\n","            if seed:\n","                np.random.seed(seed)\n","                indices = np.arange(len(self.image_list))\n","                np.random.shuffle(indices)\n","                self.image_list = self.image_list[indices]\n","                self.mask_list = self.mask_list[indices]\n","            if subset == \"Train\":\n","                self.image_names = self.image_list[:int(\n","                    np.ceil(len(self.image_list) * (1 - self.fraction)))]\n","                self.mask_names = self.mask_list[:int(\n","                    np.ceil(len(self.mask_list) * (1 - self.fraction)))]\n","            else:\n","                self.image_names = self.image_list[\n","                    int(np.ceil(len(self.image_list) * (1 - self.fraction))):]\n","                self.mask_names = self.mask_list[\n","                    int(np.ceil(len(self.mask_list) * (1 - self.fraction))):]\n","\n","    def __len__(self) -> int:\n","        return len(self.image_names)\n","\n","    def __getitem__(self, index: int) -> Any:\n","        image_path = self.image_names[index]\n","        mask_path = self.mask_names[index]\n","        with open(image_path, \"rb\") as image_file, open(mask_path,\n","                                                        \"rb\") as mask_file:\n","            image = Image.open(image_file)\n","            if self.image_color_mode == \"rgb\":\n","                image = image.convert(\"RGB\")\n","            elif self.image_color_mode == \"grayscale\":\n","                image = image.convert(\"L\")\n","            mask = Image.open(mask_file)\n","            if self.mask_color_mode == \"rgb\":\n","                mask = mask.convert(\"RGB\")\n","            elif self.mask_color_mode == \"grayscale\":\n","                mask = mask.convert(\"RGB\")\n","            sample = {\"image\": image, \"mask\": mask}\n","            if self.transforms:\n","                sample[\"image\"] = self.transforms(sample[\"image\"])\n","                sample[\"mask\"] = self.transforms(sample[\"mask\"])\n","            return sample"]},{"cell_type":"code","source":["from pathlib import Path\n","\n","\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","\n","#dataloader with folder function\n","\n","def get_dataloader_single_folder(data_dir: str,  image_folder: str = 'jpeg_images/IMAGES',\n","                                 mask_folder: str = 'jpeg_masks/MASKS',\n","                                 fraction: float = 0.2,\n","                                 batch_size: int = 4):\n","    data_transforms = transforms.Compose([transforms.Resize((320,320)),transforms.ToTensor(),\n","                                          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n","\n","    image_datasets = {\n","        x: SegmentationDataset(data_dir,\n","                               image_folder=image_folder,\n","                               mask_folder=mask_folder,\n","                               seed=100,\n","                               fraction=fraction,\n","                               subset=x,\n","                               transforms=data_transforms)\n","        for x in ['Train', 'Test']\n","    }\n","    dataloaders = {\n","        x: DataLoader(image_datasets[x],\n","                      batch_size=batch_size,\n","                      shuffle=True,\n","                      num_workers=8)\n","        for x in ['Train', 'Test']\n","    }\n","    return dataloaders"],"metadata":{"id":"yNjqIjzbmUoC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n","from torchvision import models\n","\n","\n","def createDeepLabv3(outputchannels=1):\n","    \"\"\"DeepLabv3 class with custom head\n","    Args:\n","        outputchannels (int, optional): The number of output channels\n","        in your dataset masks. Defaults to 1.\n","    Returns:\n","        model: Returns the DeepLabv3 model with the ResNet101 backbone.\n","    \"\"\"\n","    model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet101',pretained=True)\n","    model.classifier=DeepLabHead(2048,outputchannels)\n","    return model"],"metadata":{"id":"jxAGfrIefGi5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","import copy\n","import os\n","from tqdm import tqdm\n","import csv\n","from torchvision.transforms import Grayscale\n","\n","#train model\n","\n","def train_model(model, criterion, dataloaders, optimizer, metrics, bpath,\n","                num_epochs):\n","    grayscale=Grayscale()\n","    since = time.time()\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_loss = 1e10\n","    # Use gpu if available\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    # Initialize the log file for training and testing loss and metrics\n","    fieldnames = ['epoch', 'Train_loss', 'Test_loss'] + \\\n","        [f'Train_{m}' for m in metrics.keys()] + \\\n","        [f'Test_{m}' for m in metrics.keys()]\n","    with open(os.path.join(bpath, 'log.csv'), 'w', newline='') as csvfile:\n","        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","        writer.writeheader()\n","\n","    for epoch in range(1, num_epochs + 1):\n","        print('Epoch {}/{}'.format(epoch, num_epochs))\n","        print('-' * 10)\n","        # Each epoch has a training and validation phase\n","        # Initialize batch summary\n","        batchsummary = {a: [0] for a in fieldnames}\n","\n","        for phase in ['Train', 'Test']:\n","            if phase == 'Train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()  # Set model to evaluate mode\n","\n","            # Iterate over data.\n","            for sample in tqdm(iter(dataloaders[phase])):\n","                inputs = sample['image'].to(device)\n","                masks = grayscale(sample['mask']).to(device)\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'Train'):\n","                    outputs = model(inputs)\n","                    loss = criterion(outputs['out'], masks)\n","                    y_pred = outputs['out'].data.cpu().numpy().ravel()\n","                    y_true = masks.data.cpu().numpy().ravel()\n","                    for name, metric in metrics.items():\n","                        if name == 'f1_score':\n","                            # Use a classification threshold of 0.1\n","                            batchsummary[f'{phase}_{name}'].append(\n","                                metric(y_true > 0, y_pred > 0.1))\n","                        else:\n","                            batchsummary[f'{phase}_{name}'].append(\n","                                metric(y_true.astype('uint8'), y_pred))\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'Train':\n","                        loss.backward()\n","                        optimizer.step()\n","            batchsummary['epoch'] = epoch\n","            epoch_loss = loss\n","            batchsummary[f'{phase}_loss'] = epoch_loss.item()\n","            print('{} Loss: {:.4f}'.format(phase, loss))\n","        for field in fieldnames[3:]:\n","            batchsummary[field] = np.mean(batchsummary[field])\n","        print(batchsummary)\n","        with open(os.path.join(bpath, 'log.csv'), 'a', newline='') as csvfile:\n","            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","            writer.writerow(batchsummary)\n","            # deep copy the model\n","            if phase == 'Test' and loss < best_loss:\n","                best_loss = loss\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Lowest Loss: {:4f}'.format(best_loss))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model"],"metadata":{"id":"bIfB3dqifb0K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import f1_score, roc_auc_score\n","import torch\n","\n","#main function\n","\n","def main(data_directory, exp_directory, epochs, batch_size):\n","  model=createDeepLabv3() #모델 불러오기\n","  model.train() #모델 train모드\n","  data_directory=Path(data_directory)\n","  exp_directory=Path(exp_directory)\n","  if not exp_directory.exists(): #experiment directory 생성\n","    exp_directory.mkdir()\n","\n","  criterion=torch.nn.MSELoss(reduction='mean') #MSELoss 기준 model training\n","  optimizer=torch.optim.Adam(model.parameters(), lr=1e-4) #Adam Optimizer 적용\n","\n","  metrics={'auc': roc_auc_score} #auc metric\n","\n","  dataloaders=get_dataloader_single_folder(\n","      data_directory, batch_size=4 #batch_size: 4\n","  )\n","  _ = train_model(model,\n","                    criterion,\n","                    dataloaders,\n","                    optimizer,\n","                    bpath=exp_directory,\n","                    metrics=metrics,\n","                    num_epochs=epochs)\n","\n","  # Save the trained model\n","  torch.save(model, exp_directory / 'weights.pt') #학습시킨 모델 자체 저장\n","\n","\n","if __name__ == \"__main__\":\n","    main('/content/drive/MyDrive/archive', '/content/drive/MyDrive/archive/exp', 10, 4)\n"],"metadata":{"id":"dfc5XJnWlJ2h","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d956ea01-49c9-451b-eec4-6de0336854e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 200/200 [02:53<00:00,  1.15it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.0305\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 50/50 [00:18<00:00,  2.73it/s]"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 0.0353\n","{'epoch': 1, 'Train_loss': 0.030499424785375595, 'Test_loss': 0.035251326858997345, 'Train_auc': 0.906308091757105, 'Test_auc': 0.9550552369278694}\n","Epoch 2/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 200/200 [02:55<00:00,  1.14it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.0208\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 50/50 [00:18<00:00,  2.76it/s]"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 0.0291\n","{'epoch': 2, 'Train_loss': 0.020790427923202515, 'Test_loss': 0.029098767787218094, 'Train_auc': 0.9716607753076506, 'Test_auc': 0.9582287977010302}\n","Epoch 3/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 200/200 [02:54<00:00,  1.15it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.0200\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 50/50 [00:18<00:00,  2.75it/s]"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 0.0290\n","{'epoch': 3, 'Train_loss': 0.020048674196004868, 'Test_loss': 0.028985142707824707, 'Train_auc': 0.9781864590917163, 'Test_auc': 0.967815999606026}\n","Epoch 4/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 200/200 [02:55<00:00,  1.14it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.0189\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 50/50 [00:18<00:00,  2.76it/s]"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 0.0215\n","{'epoch': 4, 'Train_loss': 0.018927257508039474, 'Test_loss': 0.021460192278027534, 'Train_auc': 0.9799020330959692, 'Test_auc': 0.9660819660866254}\n","Epoch 5/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 200/200 [02:56<00:00,  1.14it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.0140\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 50/50 [00:18<00:00,  2.75it/s]"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 0.0230\n","{'epoch': 5, 'Train_loss': 0.014007017016410828, 'Test_loss': 0.023043373599648476, 'Train_auc': 0.9807130456319472, 'Test_auc': 0.965333307166314}\n","Epoch 6/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 200/200 [02:54<00:00,  1.14it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.0087\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 50/50 [00:18<00:00,  2.75it/s]"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 0.0308\n","{'epoch': 6, 'Train_loss': 0.008664727210998535, 'Test_loss': 0.03077804110944271, 'Train_auc': 0.9797588668520224, 'Test_auc': 0.9650385497608275}\n","Epoch 7/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 200/200 [02:55<00:00,  1.14it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.0109\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 50/50 [00:18<00:00,  2.76it/s]"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 0.0237\n","{'epoch': 7, 'Train_loss': 0.010947276838123798, 'Test_loss': 0.023739265277981758, 'Train_auc': 0.9794694084477851, 'Test_auc': 0.96632007344698}\n","Epoch 8/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 200/200 [02:54<00:00,  1.15it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.0091\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 50/50 [00:18<00:00,  2.74it/s]"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 0.0203\n","{'epoch': 8, 'Train_loss': 0.00913803931325674, 'Test_loss': 0.020277613773941994, 'Train_auc': 0.9783368859795355, 'Test_auc': 0.9675915389922135}\n","Epoch 9/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 200/200 [02:56<00:00,  1.14it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.0070\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 50/50 [00:18<00:00,  2.76it/s]"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 0.0145\n","{'epoch': 9, 'Train_loss': 0.006994449999183416, 'Test_loss': 0.014475295320153236, 'Train_auc': 0.9778803549471765, 'Test_auc': 0.9654035660712633}\n","Epoch 10/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 200/200 [02:55<00:00,  1.14it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.0054\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100%|██████████| 50/50 [00:18<00:00,  2.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 0.0192\n","{'epoch': 10, 'Train_loss': 0.005392581224441528, 'Test_loss': 0.019211364910006523, 'Train_auc': 0.9790272678369217, 'Test_auc': 0.963840869445187}\n","Training complete in 32m 20s\n","Lowest Loss: 0.014475\n"]}]}]}